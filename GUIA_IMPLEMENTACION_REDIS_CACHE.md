# üéì Gu√≠a para Estudiantes: Implementar Cach√© Persistente con Redis

## üìö ¬øQu√© vamos a lograr?

Implementaremos un **sistema de cach√© con Redis** para reducir el tiempo de respuesta del endpoint `/obtener-ruc/{ruc}` de **10-30 segundos** a menos de **100 milisegundos** cuando el RUC ya fue consultado anteriormente.

### ¬øPor qu√© Redis?

**Redis** es una base de datos en memoria (muy r√°pida) que act√∫a como un "almac√©n temporal" de datos. Imag√≠nalo como una libreta donde guardas las respuestas de los ex√°menes ya resueltos, para no tener que resolverlos de nuevo.

**Beneficios:**
- ‚ö° **Velocidad**: Redis guarda datos en memoria RAM (super r√°pido)
- üíæ **Persistencia**: Los datos sobreviven aunque reinicies tu aplicaci√≥n
- üîÑ **Expiraci√≥n autom√°tica**: Puedes configurar que los datos se borren despu√©s de X d√≠as
- üì¶ **F√°cil integraci√≥n**: Se conecta con Python en pocas l√≠neas de c√≥digo

---

## üó∫Ô∏è Arquitectura de la Soluci√≥n

### Antes (sin cach√©):
```
Usuario ‚Üí FastAPI ‚Üí Scraper (Selenium) ‚Üí SUNAT ‚Üí Respuesta (10-30 seg)
```

### Despu√©s (con Redis):
```
Usuario ‚Üí FastAPI ‚Üí Redis (¬øexiste?)
                      ‚îú‚îÄ S√ç  ‚Üí Respuesta instant√°nea (< 100ms) ‚úÖ
                      ‚îî‚îÄ NO  ‚Üí Scraper ‚Üí SUNAT ‚Üí Guardar en Redis ‚Üí Respuesta
```

---

## üìã Pasos de Implementaci√≥n

### **PASO 1: Configurar Docker Compose** üê≥

Docker Compose nos permite manejar **m√∫ltiples contenedores** (tu backend + Redis) de forma sencilla.

#### 1.1 Crear archivo `docker-compose.yml`

Crea este archivo en la **ra√≠z del proyecto** (al mismo nivel que `Dockerfile`):

```yaml
version: '3.8'

services:
  # ========================================
  # SERVICIO DE REDIS
  # ========================================
  redis:
    image: redis:7-alpine  # Imagen oficial de Redis (versi√≥n ligera)
    container_name: crm_redis
    ports:
      - "6379:6379"  # Puerto por defecto de Redis
    volumes:
      - redis_data:/data  # Aqu√≠ se guardan los datos de forma persistente
    command: redis-server --appendonly yes  # Habilita persistencia en disco
    networks:
      - crm_network
    restart: unless-stopped  # Se reinicia autom√°ticamente si falla
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3

  # ========================================
  # SERVICIO DEL BACKEND (FastAPI)
  # ========================================
  backend:
    build: .  # Usa el Dockerfile en la ra√≠z del proyecto
    container_name: crm_backend
    ports:
      - "8000:8000"  # Puerto de FastAPI
    environment:
      # URL de conexi√≥n a Redis (usa el nombre del servicio "redis")
      - REDIS_URL=redis://redis:6379
      - PYTHONUNBUFFERED=1
    depends_on:
      redis:
        condition: service_healthy  # Espera a que Redis est√© listo
    networks:
      - crm_network
    restart: unless-stopped

# ========================================
# VOL√öMENES (Persistencia de datos)
# ========================================
volumes:
  redis_data:
    driver: local  # Los datos de Redis se guardan en tu disco local

# ========================================
# REDES (Para que los contenedores se comuniquen)
# ========================================
networks:
  crm_network:
    driver: bridge
```

#### üí° Explicaci√≥n para estudiantes:

- **services**: Aqu√≠ defines cada "aplicaci√≥n" (Redis y Backend)
- **image**: La imagen Docker a usar (Redis 7 en versi√≥n Alpine, que es ligera)
- **ports**: Mapea puertos del contenedor a tu m√°quina (6379 es el puerto est√°ndar de Redis)
- **volumes**: Guarda los datos de Redis en tu disco para que no se pierdan
- **networks**: Permite que Backend y Redis se "vean" entre s√≠
- **depends_on**: Backend esperar√° a que Redis est√© listo antes de iniciar
- **healthcheck**: Verifica que Redis est√© funcionando correctamente

---

### **PASO 2: Instalar Dependencias de Python** üì¶

#### 2.1 Agregar Redis a `requirements.txt`

Abre tu archivo `requirements.txt` y agrega:

```txt
redis==5.0.1
```

#### 2.2 Instalar localmente (para desarrollo)

```bash
pip install redis==5.0.1
```

---

### **PASO 3: Crear Servicio de Cach√©** üõ†Ô∏è

Vamos a crear un archivo dedicado para manejar Redis de forma organizada.

#### 3.1 Crear archivo `app/infrastructure/cache/redis_cache.py`

```python
"""
Servicio de cach√© con Redis
"""
import redis
import json
import os
from typing import Optional, Dict, Any
from datetime import timedelta


class RedisCacheService:
    """
    Servicio para manejar el cach√© de datos con Redis
    """

    def __init__(self):
        """
        Inicializa la conexi√≥n a Redis
        """
        # Obtiene la URL de Redis desde variables de entorno
        # Por defecto: redis://localhost:6379 (desarrollo local)
        redis_url = os.getenv('REDIS_URL', 'redis://localhost:6379')

        try:
            self.client = redis.from_url(
                redis_url,
                decode_responses=True,  # Convierte bytes a strings autom√°ticamente
                socket_connect_timeout=5,
                socket_timeout=5
            )
            # Prueba la conexi√≥n
            self.client.ping()
            print(f"‚úÖ Conectado a Redis: {redis_url}")
        except redis.ConnectionError as e:
            print(f"‚ö†Ô∏è Error conectando a Redis: {e}")
            print("‚ö†Ô∏è El cach√© no estar√° disponible")
            self.client = None

    def get(self, key: str) -> Optional[Dict[str, Any]]:
        """
        Obtiene un valor del cach√©

        Args:
            key: Clave del cach√© (ej: "sunat:ruc:20123456789")

        Returns:
            Diccionario con los datos o None si no existe
        """
        if not self.client:
            return None

        try:
            data = self.client.get(key)
            if data:
                print(f"‚úÖ Cache HIT: {key}")
                return json.loads(data)
            else:
                print(f"‚ùå Cache MISS: {key}")
                return None
        except Exception as e:
            print(f"‚ö†Ô∏è Error obteniendo del cach√©: {e}")
            return None

    def set(
        self,
        key: str,
        value: Dict[str, Any],
        ttl_seconds: int = 604800  # 7 d√≠as por defecto
    ) -> bool:
        """
        Guarda un valor en el cach√© con tiempo de expiraci√≥n

        Args:
            key: Clave del cach√©
            value: Diccionario con los datos a guardar
            ttl_seconds: Tiempo de vida en segundos (default: 7 d√≠as)

        Returns:
            True si se guard√≥ correctamente, False si hubo error
        """
        if not self.client:
            return False

        try:
            serialized_value = json.dumps(value, ensure_ascii=False)
            self.client.setex(key, ttl_seconds, serialized_value)
            print(f"üíæ Guardado en cach√©: {key} (TTL: {ttl_seconds}s)")
            return True
        except Exception as e:
            print(f"‚ö†Ô∏è Error guardando en cach√©: {e}")
            return False

    def delete(self, key: str) -> bool:
        """
        Elimina un valor del cach√©

        Args:
            key: Clave del cach√© a eliminar

        Returns:
            True si se elimin√≥, False si hubo error
        """
        if not self.client:
            return False

        try:
            self.client.delete(key)
            print(f"üóëÔ∏è Eliminado del cach√©: {key}")
            return True
        except Exception as e:
            print(f"‚ö†Ô∏è Error eliminando del cach√©: {e}")
            return False

    def clear_pattern(self, pattern: str) -> int:
        """
        Elimina todas las claves que coincidan con un patr√≥n

        Args:
            pattern: Patr√≥n de b√∫squeda (ej: "sunat:ruc:*")

        Returns:
            N√∫mero de claves eliminadas
        """
        if not self.client:
            return 0

        try:
            keys = self.client.keys(pattern)
            if keys:
                deleted = self.client.delete(*keys)
                print(f"üóëÔ∏è Eliminadas {deleted} claves con patr√≥n: {pattern}")
                return deleted
            return 0
        except Exception as e:
            print(f"‚ö†Ô∏è Error limpiando cach√©: {e}")
            return 0

    def health_check(self) -> bool:
        """
        Verifica si Redis est√° funcionando

        Returns:
            True si Redis responde, False si no
        """
        if not self.client:
            return False

        try:
            return self.client.ping()
        except Exception:
            return False


# Singleton: Una √∫nica instancia para toda la aplicaci√≥n
_cache_service = None

def get_cache_service() -> RedisCacheService:
    """
    Obtiene la instancia √∫nica del servicio de cach√©
    """
    global _cache_service
    if _cache_service is None:
        _cache_service = RedisCacheService()
    return _cache_service
```

#### üí° Explicaci√≥n:

- **`get(key)`**: Busca un valor en Redis. Si existe, lo devuelve; si no, devuelve `None`
- **`set(key, value, ttl_seconds)`**: Guarda un valor en Redis con un tiempo de expiraci√≥n
- **`delete(key)`**: Elimina una clave espec√≠fica
- **`clear_pattern(pattern)`**: Elimina m√∫ltiples claves (ej: todos los RUCs)
- **`health_check()`**: Verifica que Redis est√© funcionando
- **Singleton**: Solo se crea una conexi√≥n a Redis para toda la aplicaci√≥n

---

### **PASO 4: Modificar el Use Case** üíª

Ahora integramos Redis en la l√≥gica de consulta de RUC.

#### 4.1 Editar `app/core/use_cases/integracion_sunat/integracion_sunat_uc.py`

```python
"""
Caso de uso para la integraci√≥n con SUNAT
"""
from typing import Dict
from app.adapters.outbound.external_services.sunat.sunat_scraper import SunatScraper
from app.infrastructure.cache.redis_cache import get_cache_service
import re
import asyncio
from selenium.common.exceptions import TimeoutException


class IntegracionSunatUC:
    """
    Caso de uso para consultar informaci√≥n de RUC en SUNAT
    """

    def __init__(self, sunat_scraper: SunatScraper):
        self.sunat_scraper = sunat_scraper
        self.cache_service = get_cache_service()  # ‚Üê NUEVO: Servicio de cach√©
        self.cache_ttl = 604800  # 7 d√≠as en segundos

    async def obtener_ruc(self, ruc: str, max_intentos: int = 3) -> Dict:
        """
        Obtiene informaci√≥n de un RUC desde SUNAT con cach√©

        Args:
            ruc (str): N√∫mero de RUC a consultar
            max_intentos (int): N√∫mero m√°ximo de intentos

        Returns:
            Dict: Informaci√≥n del RUC o error
        """
        # Validar formato de RUC
        if not self._validar_ruc(ruc):
            return {
                "message": "Error al consultar RUC",
                "detail": "El formato del RUC no es v√°lido. Debe tener 11 d√≠gitos.",
                "ruc": ruc
            }

        # ========================================
        # 1. BUSCAR EN CACH√â PRIMERO
        # ========================================
        cache_key = f"sunat:ruc:{ruc}"
        cached_data = self.cache_service.get(cache_key)

        if cached_data:
            print(f"‚úÖ Retornando datos desde cach√© para RUC: {ruc}")
            return cached_data

        # ========================================
        # 2. NO EST√Å EN CACH√â ‚Üí HACER SCRAPING
        # ========================================
        print(f"‚ùå RUC {ruc} no encontrado en cach√©, consultando SUNAT...")

        ultimo_error = None

        for intento in range(1, max_intentos + 1):
            try:
                print(f"Intento {intento}/{max_intentos} para RUC {ruc}")

                # Realizar consulta en SUNAT con modo r√°pido por defecto
                resultado = self.sunat_scraper.consultar_ruc(ruc, modo_rapido=True)

                # Verificar si hubo error en la consulta
                if "error" in resultado and resultado["razonSocial"] == "Error en consulta":
                    ultimo_error = resultado.get('error', 'Error desconocido')

                    # Verificar si es un error de timeout para recrear el driver
                    if "timeout" in ultimo_error.lower() or "timed out" in ultimo_error.lower():
                        print(f"Timeout detectado, recreando WebDriver...")
                        self.sunat_scraper.driver_manager.cleanup()
                        await asyncio.sleep(2)

                    if intento < max_intentos:
                        print(f"Error en intento {intento}, reintentando...")
                        continue
                    else:
                        return {
                            "message": "Error al consultar RUC",
                            "detail": f"No se pudo obtener informaci√≥n del RUC {ruc} despu√©s de {max_intentos} intentos. √öltimo error: {ultimo_error}",
                            "ruc": ruc
                        }

                # ========================================
                # 3. CONSULTA EXITOSA ‚Üí GUARDAR EN CACH√â
                # ========================================
                print(f"‚úÖ Consulta exitosa en intento {intento}")

                # Guardar en Redis con expiraci√≥n de 7 d√≠as
                self.cache_service.set(cache_key, resultado, self.cache_ttl)

                return resultado

            except TimeoutException as e:
                ultimo_error = f"Timeout del WebDriver: {str(e)}"
                print(f"Timeout en intento {intento}: {ultimo_error}")

                # Para errores de timeout, limpiar el driver y reintentar
                print("Recreando WebDriver debido a timeout...")
                self.sunat_scraper.driver_manager.cleanup()

                if intento < max_intentos:
                    print(f"Reintentando en 3 segundos...")
                    await asyncio.sleep(3)
                    continue

            except Exception as e:
                ultimo_error = str(e)
                print(f"Error en intento {intento}: {ultimo_error}")

                # Verificar si el error contiene indicios de timeout
                if "timeout" in ultimo_error.lower() or "timed out" in ultimo_error.lower():
                    print("Error relacionado con timeout, recreando WebDriver...")
                    self.sunat_scraper.driver_manager.cleanup()
                    await asyncio.sleep(2)
                elif "renderer" in ultimo_error.lower():
                    print("Error del renderer, recreando WebDriver...")
                    self.sunat_scraper.driver_manager.cleanup()
                    await asyncio.sleep(2)

                if intento < max_intentos:
                    print(f"Reintentando en 2 segundos...")
                    await asyncio.sleep(2)
                    continue

        # Si llegamos aqu√≠, todos los intentos fallaron
        return {
            "message": "Error al consultar RUC",
            "detail": f"Error interno al consultar el RUC {ruc} despu√©s de {max_intentos} intentos. √öltimo error: {ultimo_error}",
            "ruc": ruc
        }

    def _validar_ruc(self, ruc: str) -> bool:
        """
        Valida el formato del RUC

        Args:
            ruc (str): N√∫mero de RUC a validar

        Returns:
            bool: True si el formato es v√°lido
        """
        # El RUC debe tener exactamente 11 d√≠gitos
        if not ruc or len(ruc) != 11:
            return False

        # Debe contener solo n√∫meros
        if not ruc.isdigit():
            return False

        return True
```

---

### **PASO 5: Ejecutar con Docker Compose** üöÄ

#### 5.1 Levantar los servicios

Abre una terminal en la ra√≠z del proyecto y ejecuta:

```bash
# Construir e iniciar todos los servicios
docker-compose up --build
```

#### 5.2 Comandos √∫tiles

```bash
# Iniciar en segundo plano (detached mode)
docker-compose up -d

# Ver logs en tiempo real
docker-compose logs -f

# Ver solo logs de Redis
docker-compose logs -f redis

# Ver solo logs del backend
docker-compose logs -f backend

# Detener todos los servicios
docker-compose down

# Detener y eliminar vol√∫menes (borra datos de Redis)
docker-compose down -v

# Reiniciar un servicio espec√≠fico
docker-compose restart backend
```

#### 5.3 Verificar que funcione

1. **Probar el endpoint:**
   ```bash
   curl http://localhost:8000/obtener-ruc/20123456789
   ```

2. **Primera consulta**: Tardar√° 10-30 segundos (consulta SUNAT)
3. **Segunda consulta del mismo RUC**: Tardar√° < 100ms (desde cach√©) ‚úÖ

#### 5.4 Monitorear Redis

```bash
# Conectarse al contenedor de Redis
docker exec -it crm_redis redis-cli

# Dentro de Redis, ejecutar:
KEYS *                    # Ver todas las claves
GET sunat:ruc:20123456789 # Ver datos de un RUC espec√≠fico
TTL sunat:ruc:20123456789 # Ver tiempo restante antes de expirar
FLUSHALL                  # Borrar todo el cach√© (cuidado!)
```

---

## üß™ Testing y Validaci√≥n

### Prueba 1: Cache Miss (primera vez)
```bash
curl -w "\nTiempo: %{time_total}s\n" http://localhost:8000/obtener-ruc/20123456789
```
**Resultado esperado**: 10-30 segundos

### Prueba 2: Cache Hit (segunda vez, mismo RUC)
```bash
curl -w "\nTiempo: %{time_total}s\n" http://localhost:8000/obtener-ruc/20123456789
```
**Resultado esperado**: < 0.1 segundos ‚ö°

---

## üîß Configuraci√≥n de Producci√≥n (Railway/Render)

### Para Railway:

1. **Agregar Redis como servicio:**
   - En Railway, ve a tu proyecto
   - Click en "New" ‚Üí "Database" ‚Üí "Redis"
   - Railway crear√° una variable de entorno `REDIS_URL` autom√°ticamente

2. **Tu backend la detectar√° autom√°ticamente** porque usamos:
   ```python
   redis_url = os.getenv('REDIS_URL', 'redis://localhost:6379')
   ```

### Para Render:

1. **Crear servicio Redis:**
   - Render ofrece Redis como add-on
   - Agregar a tu servicio web
   - Configurar variable `REDIS_URL`

---

## üìä Monitoreo y M√©tricas

### Agregar endpoint de health check

```python
# En tu archivo principal de FastAPI
from app.infrastructure.cache.redis_cache import get_cache_service

@app.get("/health")
async def health_check():
    cache_service = get_cache_service()
    return {
        "status": "healthy",
        "redis": "connected" if cache_service.health_check() else "disconnected"
    }
```

---

## üéØ Resumen de Beneficios

| M√©trica | Antes | Despu√©s | Mejora |
|---------|-------|---------|--------|
| **Tiempo de respuesta (cache hit)** | 10-30s | < 100ms | **99% m√°s r√°pido** |
| **Carga en SUNAT** | 100% | 10-20% | **80-90% reducci√≥n** |
| **Experiencia de usuario** | Muy lenta | Instant√°nea | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **Costo de infraestructura** | Alto | Bajo | üí∞ Ahorro |

---

## ‚ùì FAQ (Preguntas Frecuentes)

### ¬øQu√© pasa si Redis falla?
El sistema sigue funcionando, solo que sin cach√©. Todas las consultas ir√°n directamente a SUNAT.

### ¬øCu√°nto espacio ocupa Redis?
Muy poco. Cada RUC ocupa ~2KB. Para 10,000 RUCs: ~20MB.

### ¬øCu√°ndo se eliminan los datos?
Autom√°ticamente despu√©s de 7 d√≠as (configurable con `cache_ttl`).

### ¬øPuedo invalidar el cach√© manualmente?
S√≠, usando:
```python
cache_service.delete(f"sunat:ruc:{ruc}")
```

### ¬øFunciona en desarrollo local sin Docker?
S√≠, instala Redis localmente:
```bash
# Windows (con Chocolatey)
choco install redis-64

# Mac
brew install redis

# Linux
sudo apt-get install redis-server
```

---

## üéì Conclusi√≥n

¬°Felicidades! Has implementado un sistema de cach√© profesional con Redis. Ahora tu aplicaci√≥n:

‚úÖ Es **99% m√°s r√°pida** para consultas repetidas
‚úÖ Reduce la carga en SUNAT y tu servidor
‚úÖ Mejora la experiencia del usuario dr√°sticamente
‚úÖ Est√° lista para escalar a miles de usuarios

**Pr√≥ximos pasos recomendados:**
1. Monitorear el cache hit rate
2. Ajustar TTL seg√∫n necesidades del negocio
3. Considerar migrar de Selenium a Requests (Fase 2)

---

## üöÇ Despliegue en Railway con Docker Compose

### ¬øC√≥mo funciona Railway con docker-compose?

**Respuesta corta:** Railway **NO** lee autom√°ticamente tu `docker-compose.yml` para crear servicios de Redis. Debes crear el servicio de Redis manualmente en Railway.

### üîç Explicaci√≥n detallada

#### ¬øQu√© hace Railway con docker-compose?

Railway tiene **dos formas de despliegue**:

1. **Despliegue desde Dockerfile** (recomendado para Railway)
2. **Despliegue con docker-compose** (limitado)

**Importante:** Cuando subes tu proyecto a Railway:
- Railway **detecta** si tienes un `Dockerfile` y lo usa para construir tu backend
- Railway **NO crea autom√°ticamente** servicios adicionales (como Redis) desde el `docker-compose.yml`
- El archivo `docker-compose.yml` es **solo para desarrollo local**

### üìã Proceso de despliegue en Railway (Paso a Paso)

#### **Opci√≥n 1: Usando el Dockerfile (RECOMENDADO)**

##### 1Ô∏è‚É£ **Crear el servicio de Redis en Railway**

1. Ve a tu proyecto en Railway
2. Click en **"New"** ‚Üí **"Database"** ‚Üí **"Add Redis"**
3. Railway crear√° autom√°ticamente:
   - Un servicio de Redis completamente configurado
   - Una variable de entorno `REDIS_URL` con la URL de conexi√≥n
   - Ejemplo: `redis://default:password@redis.railway.internal:6379`

##### 2Ô∏è‚É£ **Desplegar tu Backend en Railway**

1. En Railway, click en **"New"** ‚Üí **"GitHub Repo"**
2. Selecciona tu repositorio
3. Railway detectar√° tu `Dockerfile` autom√°ticamente
4. Configura las variables de entorno:
   - `REDIS_URL` ya estar√° configurada autom√°ticamente si agregaste Redis primero
   - Agrega otras variables que necesites (API keys, secrets, etc.)

##### 3Ô∏è‚É£ **Conectar Backend con Redis**

Railway autom√°ticamente:
- Crea una red privada entre tus servicios
- Inyecta la variable `REDIS_URL` en tu backend
- Tu c√≥digo en `redis_cache.py` la detectar√°:
  ```python
  redis_url = os.getenv('REDIS_URL', 'redis://localhost:6379')
  ```

##### 4Ô∏è‚É£ **Verificar el despliegue**

```bash
# Probar el endpoint
curl https://tu-proyecto.up.railway.app/health

# Deber√≠as ver:
{
  "status": "healthy",
  "redis": "connected"
}
```

---

#### **Opci√≥n 2: Forzar uso de docker-compose en Railway (NO RECOMENDADO)**

‚ö†Ô∏è **Limitaciones importantes:**
- Railway tiene soporte limitado para docker-compose
- No es la forma recomendada por Railway
- Puede tener problemas con networking entre contenedores

Si a√∫n as√≠ quieres intentarlo:

##### 1Ô∏è‚É£ Crear archivo `railway.toml`

```toml
[build]
builder = "dockerfile"
dockerfilePath = "Dockerfile"

[deploy]
startCommand = "docker-compose up"
restartPolicyType = "on_failure"
```

##### 2Ô∏è‚É£ Modificar `docker-compose.yml` para producci√≥n

```yaml
version: '3.8'

services:
  redis:
    image: redis:7-alpine
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    # Quitar ports - Railway maneja esto internamente

  backend:
    build: .
    environment:
      - REDIS_URL=redis://redis:6379  # Usar nombre del servicio
    depends_on:
      - redis

volumes:
  redis_data:
```

**Problema:** Railway puede tener dificultades con vol√∫menes persistentes y networking.

---

### üéØ Recomendaci√≥n Final: Arquitectura Multi-Servicio

**La forma correcta en Railway:**

```
Railway Project
‚îú‚îÄ‚îÄ üóÑÔ∏è Redis Database (creado manualmente)
‚îÇ   ‚îî‚îÄ‚îÄ Genera: REDIS_URL=redis://...railway.internal:6379
‚îÇ
‚îî‚îÄ‚îÄ üêç Backend Service (desde Dockerfile)
    ‚îî‚îÄ‚îÄ Lee: process.env.REDIS_URL
```

### üìù Checklist para desplegar en Railway

- [ ] Crear servicio de Redis en Railway manualmente
- [ ] Verificar que Railway gener√≥ la variable `REDIS_URL`
- [ ] Subir tu repositorio a GitHub
- [ ] Conectar Railway con tu repositorio
- [ ] Railway detectar√° tu `Dockerfile` autom√°ticamente
- [ ] Verificar que el backend se conecte a Redis
- [ ] Probar endpoint `/health` para confirmar conexi√≥n

### üÜö Comparaci√≥n: Local vs Railway

| Aspecto | Desarrollo Local | Railway |
|---------|------------------|---------|
| **Redis** | `docker-compose up` lo crea | Debes crearlo manualmente |
| **Networking** | Docker network autom√°tico | Railway network privado |
| **Variables** | `.env` o `docker-compose.yml` | Panel de Railway |
| **docker-compose.yml** | ‚úÖ Usado | ‚ùå Ignorado (solo usa Dockerfile) |
| **Persistencia** | Volumen local | Volumen gestionado por Railway |

### ‚ùì Preguntas Frecuentes sobre Railway

#### ¬øPor qu√© Railway no lee mi docker-compose.yml?

Railway est√° optimizado para **microservicios independientes**, no para orquestar m√∫ltiples contenedores desde un solo archivo. Esto da m√°s flexibilidad para escalar cada servicio por separado.

#### ¬øNecesito modificar mi c√≥digo para Railway?

**No.** Tu c√≥digo ya est√° preparado porque usa `os.getenv('REDIS_URL')`, que funciona tanto localmente como en Railway.

#### ¬øQu√© pasa con los datos de Redis en Railway?

Railway mantiene los datos de Redis de forma persistente. Solo se borrar√°n si eliminas el servicio.

#### ¬øPuedo usar el mismo docker-compose.yml para otros servicios de nube?

S√≠, servicios como **Render**, **DigitalOcean App Platform** o **AWS** tienen mejor soporte para docker-compose que Railway.

#### ¬øCu√°nto cuesta Redis en Railway?

Railway cobra por:
- Uso de recursos (RAM/CPU)
- Plan gratuito: $5 USD de cr√©dito/mes
- Redis t√≠picamente usa ~10-50 MB RAM

---

### üéì Resumen: Docker Compose en Railway

**TL;DR:**

1. ‚ùå Railway **NO** lee `docker-compose.yml` autom√°ticamente
2. ‚úÖ `docker-compose.yml` es **solo para desarrollo local**
3. ‚úÖ En Railway, crea Redis **manualmente** desde el panel
4. ‚úÖ Railway conecta servicios autom√°ticamente con variables de entorno
5. ‚úÖ Tu c√≥digo funciona igual en local y en Railway (gracias a `REDIS_URL`)

**Flujo correcto:**

```bash
# Local (desarrollo)
docker-compose up  # Crea Redis + Backend autom√°ticamente

# Railway (producci√≥n)
1. Crear Redis manualmente en Railway
2. Desplegar Backend desde GitHub
3. Railway conecta ambos autom√°ticamente
```